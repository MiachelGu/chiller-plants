{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import common\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raining data = mid June-mid July, test data = mid of Juy to Aug\n",
    " \n",
    "1)      Tonnage prediction\n",
    "Y = loadsys\n",
    "Features = drybulb, relative humidity (rh), Time Stamp (weekdays/weekends), hour\n",
    " \n",
    "2)      Chiller plant\n",
    "Y = systotpow\n",
    "Features = loadsys, Time Stamp (weekdays/weekends), hour, dry bulb, and relative humidity (rh)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'common' from '/usa/suryak/Notebooks/chiller-plants/notebooks/common.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CacheInfo(hits=0, misses=1, maxsize=None, currsize=1)\n"
     ]
    }
   ],
   "source": [
    "df = common.load_df(\"../data/insead\", \"*.csv\")\n",
    "print(common.load_df.cache_info())\n",
    "\n",
    "# process. at last, normalize.\n",
    "_cols = [\"drybulb\", \"loadsys\", \"rh\", \"systotpower\"]\n",
    "df = common.Process.replace_nulls(df, cols=_cols)\n",
    "df = common.Process.replace_with_zero(df, cols=_cols)\n",
    "df = common.Process.set_ctwk_total(df, cols=_cols)\n",
    "df = common.Process.get_normalized_df(df, scale=(0.1, 1), cols=_cols)\n",
    "\n",
    "# add few more features.\n",
    "df[\"weekday\"] = df.index.weekday\n",
    "df[\"weekend\"] = df.weekday.apply(lambda x: int(x in (5,6)))\n",
    "df[\"hour\"] = df.index.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "```\n",
    "X = DB, Rh, Hour, Weekday\n",
    "y = Loadsys\n",
    "\n",
    "Train: Mid Jun-Jul\n",
    "Test: Mid Jul-Aug\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43000, 1, 20) (43000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# manually select training and validaiton data.\n",
    "batch_size = 200\n",
    "train_df = df[\"2016-06-15\":\"2016-07-14\"]\n",
    "validation_df = df[\"2016-07-15\":\"2016-08-14\"]\n",
    "\n",
    "# The recipe.\n",
    "features = [\"drybulb\", \"rh\", \"hour\", \"weekend\"]\n",
    "target = [\"loadsys\"]\n",
    "lookback = 5\n",
    "\n",
    "# Prepare features and target vectors\n",
    "train_x, train_y = common.prepare_keras_data(train_df, features, target, lookback, batch_size)\n",
    "validation_x, validation_y = common.prepare_keras_data(validation_df, features, target, lookback, batch_size)\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(20, batch_input_shape=(batch_size, train_x.shape[1], train_x.shape[2]), stateful=True, return_sequences=True),\n",
    "    LSTM(40, stateful=True, return_sequences=True),\n",
    "    LSTM(40, stateful=True, return_sequences=True),\n",
    "    LSTM(10, stateful=True, return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=mean_squared_error,\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\", mean_absolute_percentage_error]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch  0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(150):\n",
    "    history = model.fit(\n",
    "        x=train_x,\n",
    "        y=train_y,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        shuffle=False,\n",
    "        epochs=1,\n",
    "        validation_data=(validation_x, validation_y),\n",
    "        callbacks=[TensorBoard(log_dir=\"../output/keras1\")])\n",
    "    model.reset_states()\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"At epoch \", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
