{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load all csv files of North-point site. Concatenate them..\n",
    "data_src = \"../data\"\n",
    "data_dst = \"../output\"\n",
    "all_files = glob.glob(os.path.join(data_src, \"np\", \"*.csv\"))\n",
    "df = pd.concat([pd.read_csv(f, low_memory=False) for f in all_files], ignore_index=True)\n",
    "\n",
    "# minor changes\n",
    "df = df.rename(columns={\"Time Stamp\": \"timestamp\"})\n",
    "df = df.replace(\"\\\\N\", np.nan)\n",
    "\n",
    "# update data types. object is taken as default\n",
    "dtypes = dict([(col, np.float64) for col in df.columns])\n",
    "dtypes[\"timestamp\"] = \"datetime64[ns]\"\n",
    "df = df.astype(dtypes)\n",
    "\n",
    "# change the index to timestamp.\n",
    "df.index = df.timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Split the time series into chunks. Each chunk breaks when the field value is null. Train all the chunks separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample time series. Let's select a period and model for that.. \n",
    "ts = df[\"2017-01-01\": \"2017-01-7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing: Interpolate null values in the `fields`\n",
    "# Note: This does not eliminate all null values if their continuous sequence > window size.\n",
    "fields = [\"loadsys\", \"wetbulb\", \"ct1kw\", \"ct2kw\", \"ct3kw\", \"cwshdr\"]\n",
    "rolling_avg = ts[fields].rolling(10, min_periods=1).mean()\n",
    "\n",
    "# the time series after some sanitization\n",
    "ts = ts[fields].fillna(rolling_avg).fillna(method=\"ffill\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split the dataframe for training and validation\n",
    "# dataframe  := Pandas dataframe\n",
    "# ratio := Float, training:validation\n",
    "def train_validation_split(dataframe, ratio):\n",
    "    size = len(dataframe)\n",
    "    train_df = dataframe.iloc[0:int(size*ratio)]\n",
    "    validation_df = dataframe.iloc[int(size*ratio):]\n",
    "    return train_df, validation_df\n",
    "\n",
    "train_df, validation_df = train_validation_split(ts, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7049, 30)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare feature vectors. the hypothesis is that\n",
    "# y(t) can be determined using x1(k), x2(k), x3(k).... for all k = {t-1, t-2, t-3, ... t-N}, where 0 <= N <= t-1\n",
    "def prepare_features(dataframe, target_field, N=1):\n",
    "    x, y = [], []\n",
    "    for i in range(len(dataframe)-N-1):\n",
    "        x.append(dataframe.values[i:i+N])\n",
    "        y.append(dataframe[target_field].values[i+N])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n",
    "\n",
    "train_x, train_y = prepare_features(train_df, target_field=\"cwshdr\", N=5)\n",
    "validation_x, validation_y = prepare_features(validation_df, target_field=\"cwshdr\", N=5)\n",
    "\n",
    "# reshape data. combine all data points corresponding to a y(t)\n",
    "reshape = lambda a: a.reshape((a.shape[0], a.shape[1] * a.shape[2]))\n",
    "train_x = reshape(train_x)\n",
    "validation_x = reshape(validation_x)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(10, input_shape=(None, train_x.shape[1]), return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    LSTM(20, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=mean_squared_error, optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7049 samples, validate on 3018 samples\n",
      "Epoch 1/10000\n",
      "7049/7049 [==============================] - 8s - loss: 693.0934 - acc: 0.0000e+00 - val_loss: 576.9970 - val_acc: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "7049/7049 [==============================] - 5s - loss: 392.7820 - acc: 0.0000e+00 - val_loss: 232.6399 - val_acc: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "3232/7049 [============>.................] - ETA: 2s - loss: 218.8020 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# This is how keras wants!!\n",
    "reshape_x = lambda a: a.reshape((a.shape[0], 1, a.shape[1]))\n",
    "reshape_y = lambda a: a.reshape((a.shape[0], 1, 1))\n",
    "\n",
    "history = model.fit(\n",
    "    x=reshape_x(train_x),\n",
    "    y=reshape_y(train_y),\n",
    "    validation_data=(reshape_x(validation_x), reshape_y(validation_y)),\n",
    "    epochs=10000,\n",
    "    shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
