{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values\n",
    "\n",
    "1. This notebook explores the approaches to handle missing values\n",
    "2. INSEAD Chiller Plant data is first considered. However, North Point would be ideal (let's probably use it as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = common.load_df(\"../data/insead\", \"*21*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace nulls with rolling mean or near ones\n",
    "def replace_nulls(df, cols=[]):\n",
    "    cols = cols or df.columns\n",
    "    mean = df[cols].rolling(5, min_periods=1).mean()\n",
    "    df[cols] = df[cols].fillna(mean)\n",
    "    df[cols] = df[cols].fillna(method=\"pad\")\n",
    "    return df\n",
    "\n",
    "# create binary cols. 1 if > thresh, 0 if <= thresh\n",
    "def create_binary_cols(df, cols=[], thresh=0.1):\n",
    "    cols = cols or df.columns\n",
    "    for c in cols:\n",
    "        binzr = preprocessing.Binarizer(thresh).fit(df[c])\n",
    "        df[c + \"_bin\"] = binzr.transform(df[c])\n",
    "    return df\n",
    "\n",
    "# set values < thresh to 0\n",
    "def replace_with_zero(df, cols=[], thresh=0.1):\n",
    "    cols = cols or df.columns\n",
    "    cols = [i for i in cols if not i.endswith(\"_bin\")] # ignore step 2 cols\n",
    "    for c in cols:\n",
    "        df.loc[df[c] < thresh, c] = 0\n",
    "    return df\n",
    "\n",
    "    \n",
    "# replace values < thresh with near values\n",
    "def replace_with_near(df, cols=[], thresh=0.1):\n",
    "    cols = cols or df.columns\n",
    "    cols = [i for i in cols if not i.endswith(\"_bin\")] # ignore step 2 cols\n",
    "    for c in cols:\n",
    "        df.loc[df[c] < thresh, c] = np.nan\n",
    "    df[cols] = df[cols].fillna(method=\"pad\")\n",
    "    return df\n",
    "\n",
    "        \n",
    "# create ctkw total\n",
    "def set_ctwk_total(df, cols=[]):\n",
    "    cols = cols or df.columns\n",
    "    ctkw_cols = [i for i in cols if i.startswith(\"ct\") and i.endswith(\"kw\")]\n",
    "    df[\"cwkw_sum\"] = df[ctkw_cols].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# remove random noise. do some soft smoothing.\n",
    "def smooth_data(df, cols=[]):\n",
    "    cols = cols or df.columns\n",
    "    df[cols] = df[cols].rolling(10, min_periods=1).mean()\n",
    "\n",
    "# create chunks. break when values are < thresh\n",
    "def create_chunks(df, cols=[], thresh=0.1):\n",
    "    cols = cols or df.columns\n",
    "    cols = [i for i in cols if not i.endswith(\"_bin\")]\n",
    "    \n",
    "    df = df.copy()\n",
    "    df[df[cols] < thresh] = np.nan\n",
    "\n",
    "    chunks = []\n",
    "    break_len = 0\n",
    "    start = 0\n",
    "    end = min(0, df.shape[0]-1)\n",
    "    has_null = lambda d, row: np.any(np.isnan(d.loc[row, cols].values))\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if has_null(d, i):\n",
    "            break_len += 1\n",
    "        else:\n",
    "            if break_len != 0: start = i\n",
    "            break_len = 0\n",
    "\n",
    "        if break_len == 1 or i == df.shape[0]-1:\n",
    "            end = i-1\n",
    "            if i == df.shape[0]-1 and not has_null(d, i):\n",
    "                end = i\n",
    "            chunks.append((start, end))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (6, 9), (11, 12), (14, 16), (18, 18)]\n"
     ]
    }
   ],
   "source": [
    "d = pd.DataFrame({\"A\": [1,2,3, np.nan, np.nan, np.nan, 4,5,6,7,np.nan,1,2,np.nan,1,2,3,np.nan,1], \n",
    "                  \"B\": [1,2,3, np.nan, np.nan, np.nan, 4,5,6,7,np.nan,1,2,np.nan,1,2,3,np.nan,1]})\n",
    "chunks = step_7(d, thresh=2)     \n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_approach_1(df, cols=[]):\n",
    "    pipeline = [\n",
    "        replace_nulls,\n",
    "        create_binary_cols,\n",
    "        replace_with_zero,\n",
    "        set_ctwk_total,\n",
    "        smooth_data,\n",
    "    ]\n",
    "    for func in pipeline:\n",
    "        df = func(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_approach_2(df, cols=[]):\n",
    "    pipeline = [\n",
    "        replace_nulls,\n",
    "        create_binary_cols,\n",
    "        replace_with_near,\n",
    "        set_ctwk_total,\n",
    "        smooth_data,\n",
    "    ]\n",
    "    for func in pipeline:\n",
    "        df = func(df)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
